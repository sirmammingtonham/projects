{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "hw4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNILVuGQf+rJXqc8mwiw61F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit ('geopandas': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "3387528f949e08a7465409a492fe128ebdb03217a22eb98a1ae9d56d862b3753"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/sirmammingtonham/projects/blob/main/hw4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In your project, you will pick a dataset and an associated problem that can be solved via\n",
        "sequence models. You must describe why you need sequence models to solve this problem.\n",
        "Include a link to the dataset source. Next, you should pick an RNN framework that you would\n",
        "use to solve this problem (This framework can be in TensorFlow, PyTorch or any other Python\n",
        "Package). "
      ],
      "metadata": {
        "id": "qK2QVE5BCSPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am trying to solve the problem of classifying toxic speech online. I chose a dataset that has examples of toxic and normal comments: https://www.kaggle.com/fizzbuzz/cleaned-toxic-comments.\n",
        "\n",
        "I will implement my rnns in tensorflow."
      ],
      "metadata": {
        "id": "jW9Oh2aHO9Yu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "hbL7fzSqPRk7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "SEED = 2010"
      ],
      "outputs": [],
      "metadata": {
        "id": "PvzHnag5RjO6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "df = pd.read_csv('data/train_preprocessed.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "s_FaUI8kPXTk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>insult</th>\n",
              "      <th>obscene</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>threat</th>\n",
              "      <th>toxic</th>\n",
              "      <th>toxicity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>49999.000000</td>\n",
              "      <td>49999.000000</td>\n",
              "      <td>49999.000000</td>\n",
              "      <td>49999.000000</td>\n",
              "      <td>49999.000000</td>\n",
              "      <td>49999.000000</td>\n",
              "      <td>49999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.008860</td>\n",
              "      <td>0.048981</td>\n",
              "      <td>0.052901</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.003360</td>\n",
              "      <td>0.097662</td>\n",
              "      <td>0.222064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.093712</td>\n",
              "      <td>0.215830</td>\n",
              "      <td>0.223838</td>\n",
              "      <td>0.100967</td>\n",
              "      <td>0.057869</td>\n",
              "      <td>0.296860</td>\n",
              "      <td>0.752364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       identity_hate        insult       obscene  severe_toxic        threat  \\\n",
              "count   49999.000000  49999.000000  49999.000000  49999.000000  49999.000000   \n",
              "mean        0.008860      0.048981      0.052901      0.010300      0.003360   \n",
              "std         0.093712      0.215830      0.223838      0.100967      0.057869   \n",
              "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max         1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "              toxic      toxicity  \n",
              "count  49999.000000  49999.000000  \n",
              "mean       0.097662      0.222064  \n",
              "std        0.296860      0.752364  \n",
              "min        0.000000      0.000000  \n",
              "25%        0.000000      0.000000  \n",
              "50%        0.000000      0.000000  \n",
              "75%        0.000000      0.000000  \n",
              "max        1.000000      6.000000  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "reIJxpGTPcZV",
        "outputId": "6d3b26d4-7479-4d9a-9cd2-da5c2d209fec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "df['toxic'].sort_values().plot.hist(bins=2) # plot label distribution"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "df['comment_text'].str.split().str.len().describe() # sentence length statistics"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    49999.000000\n",
              "mean        68.371387\n",
              "std        101.938259\n",
              "min          0.000000\n",
              "25%         17.000000\n",
              "50%         36.000000\n",
              "75%         76.000000\n",
              "max       1403.000000\n",
              "Name: comment_text, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "len(df)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49999"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "split dataset into training, validation, and test sets using stratified random sampling"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "trainvalid_df, test_df = train_test_split(df, test_size=0.1, random_state=SEED, stratify=df['toxic'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "guUH6fIySOrx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "train_df, valid_df = train_test_split(trainvalid_df, test_size=0.1, random_state=SEED, stratify=trainvalid_df['toxic'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "y2dsKZLRRZat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1 (60 points):\n",
        "###Part 1 (35 points): \n",
        "Implement your RNN either using an existing framework OR you can\n",
        "implement your own RNN cell structure. In either case, describe the structure of your\n",
        "RNN and the activation functions you are using for each time step and in the output\n",
        "layer. Define a metric you will use to measure the performance of your model (NOTE:\n",
        "Performance should be measured both for the validation set and the test set)."
      ],
      "metadata": {
        "id": "VkM-tqo2Ot_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "id": "8fdQR8RdxGid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df['comment_text'], train_df['toxic']))\r\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((valid_df['comment_text'], valid_df['toxic']))\r\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_df['comment_text'], test_df['toxic']))"
      ],
      "outputs": [],
      "metadata": {
        "id": "1apYBU-LyKOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "BUFFER_SIZE = 10000\r\n",
        "BATCH_SIZE = 64"
      ],
      "outputs": [],
      "metadata": {
        "id": "keKc2g7LzBsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "shuffle, batch, and prefetch data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\r\n",
        "valid_ds = valid_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\r\n",
        "test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Gs2LrguOzDCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "setup encoder to tokenize text into vectors for use in rnn"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "encoder = tf.keras.layers.TextVectorization()\r\n",
        "encoder.adapt(train_ds.map(lambda text, label: text))"
      ],
      "outputs": [],
      "metadata": {
        "id": "cUxN9lVezYFz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "len(encoder.get_vocabulary())"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75804"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfcWUtslzc6F",
        "outputId": "e9b9982d-6cfb-48a9-de4a-49bb0ec9d6a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "NUM_LAYERS = 2"
      ],
      "outputs": [],
      "metadata": {
        "id": "fZZnKJpx1-qy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    encoder, # tokenize input text\r\n",
        "    tf.keras.layers.Embedding(\r\n",
        "        input_dim=len(encoder.get_vocabulary()),\r\n",
        "        output_dim=64,\r\n",
        "        # Use masking to handle the variable sequence lengths\r\n",
        "        mask_zero=True),\r\n",
        "    tf.keras.layers.Bidirectional(\r\n",
        "        tf.keras.layers.RNN([\r\n",
        "          tf.keras.layers.SimpleRNNCell(64, activation='relu') for _ in range(NUM_LAYERS)\r\n",
        "        ])), # bidirectional rnn with relu activation and 2 cells\r\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(1)\r\n",
        "])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Byz_t01YzuZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n",
        "              metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "5W7wbjon2NA3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "history = model.fit(train_ds, epochs=1,\r\n",
        "                    validation_data=valid_ds,\r\n",
        "                    validation_steps=30)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "633/633 [==============================] - 4112s 6s/step - loss: 0.2910 - accuracy: 0.9023 - val_loss: 0.2184 - val_accuracy: 0.8948\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jiwir-Jv24Rz",
        "outputId": "65ff64c7-c14e-4f05-bc00-b3f5f8bea7f7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "test_loss, test_acc = model.evaluate(test_ds)\r\n",
        "\r\n",
        "print('Test Loss:', test_loss)\r\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 30s 374ms/step - loss: 0.2033 - accuracy: 0.9024\n",
            "Test Loss: 0.20326177775859833\n",
            "Test Accuracy: 0.902400016784668\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "51pTopVB3KfD",
        "outputId": "0d9eaaef-7784-4a79-a536-ba9ec51b406e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:** \r\n",
        "I implemented a 2 cell bidirectional rnn with relu activations. Additionally, I tokenized the inputs and added an embedding layer.\r\n",
        "\r\n",
        "I computed classification accuracy on both the training and test set. It took a long time to train, so I had to reduce the epochs to only 1 so I could iterate on the model. Despite this, the accuracy is fairly good, with a validation accuracy of 89% and a higher test set accuracy of 90%, indicating that the model did not overfit."
      ],
      "metadata": {
        "id": "lIVl9Natdx3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part 2 (25 points): \n",
        "Update your network from part 1 with either an LSTM or a GRU\n",
        "based cell structure. Re-do the training and performance evaluation. What are the\n",
        "major differences you notice? Why do you think those differences exist between the 2\n",
        "implementations?\n"
      ],
      "metadata": {
        "id": "Yz61snkcOuGB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    encoder, # tokenize input text\r\n",
        "    tf.keras.layers.Embedding(\r\n",
        "        input_dim=len(encoder.get_vocabulary()),\r\n",
        "        output_dim=64,\r\n",
        "        # Use masking to handle the variable sequence lengths\r\n",
        "        mask_zero=True),\r\n",
        "    tf.keras.layers.Bidirectional(\r\n",
        "        tf.keras.layers.GRU(64, activation='relu')), # bidirectional GRU with relu activation\r\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(1)\r\n",
        "])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "metadata": {
        "id": "osspKHc930UO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n",
        "              metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "gKQxYjej3-qE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "history = model.fit(train_ds, epochs=2,\r\n",
        "                    validation_data=valid_ds,\r\n",
        "                    validation_steps=30)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "633/633 [==============================] - 4973s 8s/step - loss: nan - accuracy: 0.9023 - val_loss: nan - val_accuracy: 0.8990\n",
            "Epoch 2/2\n",
            "633/633 [==============================] - 5014s 8s/step - loss: nan - accuracy: 0.9023 - val_loss: nan - val_accuracy: 0.9042\n"
          ]
        }
      ],
      "metadata": {
        "id": "2I3DwM_R3_2R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "test_loss, test_acc = model.evaluate(test_ds)\r\n",
        "\r\n",
        "print('Test Loss:', test_loss)\r\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 41s 522ms/step - loss: nan - accuracy: 0.9024\n",
            "Test Loss: nan\n",
            "Test Accuracy: 0.902400016784668\n"
          ]
        }
      ],
      "metadata": {
        "id": "rMMDRMxI4BBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:** \r\n",
        "For this part I used the same general model structure as before, but I swapped the RNN cells for a single GRU cell. \r\n",
        "The accuracy is slightly higher than the simple RNN on the validation set and similar on the test set, though this might be because I was able to train it for an additional epoch since the training time was less overall. I think the reason the performance is fairly similar is since the average length of text in the dataset is fairly small, so the improved long term dependency provided by the GRU is not as needed as in other datasets."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2 (40 points):\n",
        "In this task, use any of the pre-trained word embeddings. The Wor2vec embedding link\n",
        "provided with the lecture notes can be useful to get started. Write your own code/function that\n",
        "uses these embeddings and outputs cosine similarity and a dissimilarity score for any 2 pair of\n",
        "words (read as user input). The dissimilarity score should be defined by you. You either can\n",
        "have your own idea of a dissimilarity score or refer to literature (cite the paper you used). In\n",
        "either case clearly describe how this score helps determine the dissimilarity between 2 words"
      ],
      "metadata": {
        "id": "hIjSnlwLOuKg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "import tensorflow_hub as hub"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\r\n",
        "pretrained_embeddings = hub.KerasLayer(module_url) # using pretrained universal sentence encoder embeddings"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "def similarity_dissimilarity():\r\n",
        "  a = str(input('Please enter first word: '))\r\n",
        "  b = str(input('Please enter second word: '))\r\n",
        "  a_embedding = pretrained_embeddings([a])[0].numpy() # get the embeddings for the word\r\n",
        "  b_embedding = pretrained_embeddings([b])[0].numpy()\r\n",
        "  sim = np.inner(a_embedding, b_embedding)/(np.linalg.norm(a_embedding)*np.linalg.norm(b_embedding)) # cosine similarity\r\n",
        "  dissim = 1 - sim # 1 - cosine similarity, i.e cosine distance\r\n",
        "  print(f'Similarity of {a} and {b} is {sim}. (cosine similarity)')\r\n",
        "  print(f'Dissimilarity of {a} and {b} is {dissim}. (cosine distance)')\r\n",
        "  return sim, dissim"
      ],
      "outputs": [],
      "metadata": {
        "id": "d78H2C4k5O6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "source": [
        "similarity_dissimilarity()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity of hello and hi is 0.9013519287109375. (cosine similarity)\n",
            "Dissimilarity of hello and hi is 0.0986480712890625. (cosine distance)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9013519, 0.0986480712890625)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**: I defined my dissimilarity score as 1-(cosine similarity), which is equivalent to the cosine distance. I think this is a good measure of dissimilarity since the dissimilarity should be inversely proportional to the similarity, and if two words are dissimilar we can expect them to have a larger distance between the two vectors (larger cosine distance)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# initial pytorch attempt below\r\n",
        "\r\n",
        "I initially tried implementing the rnn in pytorch, but I couldn't find any good resources on passing embeddings to an rnn layer so I decided to switch to tensorflow (it was also really tedious to set up a dataloader in pytorch)"
      ],
      "metadata": {
        "id": "n11qG61owxA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from torchtext.data.utils import get_tokenizer\r\n",
        "from torchtext.vocab import build_vocab_from_iterator\r\n",
        "\r\n",
        "tokenizer = get_tokenizer('basic_english')\r\n",
        "\r\n",
        "def yield_tokens(data_iter):\r\n",
        "  for _, text in data_iter:\r\n",
        "    yield tokenizer(text)"
      ],
      "outputs": [],
      "metadata": {
        "id": "MLqlSsxeXi6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>'])\r\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "QlZY1wGOYoFe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\r\n",
        "label_pipeline = lambda x: int(x)"
      ],
      "outputs": [],
      "metadata": {
        "id": "3Q_B0k5SZmkq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "def collate_batch(batch):\n",
        "  label_list, text_list, offsets = [], [], [0]\n",
        "  for (_label, _text) in batch:\n",
        "    label_list.append(label_pipeline(_label))\n",
        "    processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "    offsets.append(processed_text.size(0))\n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  # print(label_list.shape)\n",
        "  text_list = torch.cat(text_list)\n",
        "  return label_list.to(device), text_list.to(device), offsets.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kb05BixvZyVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from torch import nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, embed_dim, hidden_dim, n_layers):\n",
        "    super(RNN, self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    # start with embedding layer\n",
        "    self.embedding = nn.EmbeddingBag(input_size, embed_dim, sparse=True)\n",
        "    # rnn layers\n",
        "    self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers, batch_first=True, nonlinearity='relu')\n",
        "    # fully connected layer\n",
        "    self.fc = nn.Linear(hidden_dim, 2)\n",
        "    # sigmoid activation\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x, offsets):\n",
        "    print(x.shape)\n",
        "    print(x.size(0))\n",
        "    # init hidden state\n",
        "    hidden = self.init_hidden(x.size(0))\n",
        "    x = self.embedding(x, offsets)\n",
        "    print(x)\n",
        "    print(x.shape)\n",
        "    x, hidden = self.rnn(x, hidden)\n",
        "\n",
        "    x = x.contiguous().view(-1, self.hidden_dim)\n",
        "    x = self.fc(x)\n",
        "    x = self.sigmoid(x) # sigmoid output\n",
        "    return x, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    # generate the first hidden state of zeros\n",
        "    return torch.zeros(self.n_layers, batch_size, self.hidden_dim)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7QZ7qST3PPli"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def train(dataloader):\n",
        "  model.train()\n",
        "  total_acc, total_count = 0, 0\n",
        "  log_interval = 500\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    predicted_label = model(text, offsets)\n",
        "    loss = criterion(predicted_label, label)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) # try to avoid exploding gradients by clipping\n",
        "    optimizer.step()\n",
        "    total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "    total_count += label.size(0)\n",
        "    if idx % log_interval == 0 and idx > 0:\n",
        "      elapsed = time.time() - start_time\n",
        "      print(f'| epoch {epoch:3} | {idx:5}/{len(dataloader):5} batches '\n",
        "            f'| accuracy {total_acc/total_count:8.3}')\n",
        "      total_acc, total_count = 0, 0\n",
        "      start_time = time.time()"
      ],
      "outputs": [],
      "metadata": {
        "id": "o8wjNmQMe1d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_acc, total_count = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "      print(label)\n",
        "      print(text)\n",
        "      predicted_label = model(text, offsets)\n",
        "      loss = criterion(predicted_label, label)\n",
        "      total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "      total_count += label.size(0)\n",
        "  return total_acc/(total_count+1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9U_KPGL8faWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 10\n",
        "LR = 0.1\n",
        "BATCH_SIZE = 64"
      ],
      "outputs": [],
      "metadata": {
        "id": "7STVUbpxgF-x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = RNN(input_size=len(vocab), embed_dim=64, hidden_dim=12, n_layers=5).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "S0TyvF-PgIbL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_dataloader = DataLoader(list(train_iter), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(list(valid_iter), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(list(test_iter), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)"
      ],
      "outputs": [],
      "metadata": {
        "id": "URcCWWFrkb3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "list(train_iter)[0][1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  so we basically agree except on the amount of quoting we do  right  my contention is that cutting down those two quotes so drastically misses of crucial information  in the case of krugman  we are missing his justification for calling it astroturfing and in the case of maddow we are excluding her use of the actual word  which seems rather important  '"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "9PTi7ur9tm7w",
        "outputId": "2009092e-5661-47c3-fe15-18e6f6e92520"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "next(enumerate(train_dataloader))[1][2]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0,   61,   95,  225,  251,  349,  385,  414,  469,  668,  688,  766,\n",
              "         812,  854,  858,  977, 1022, 1059, 1107, 1143, 1167, 1181, 1197, 1235,\n",
              "        1342, 1363, 1405, 1452, 1484, 1533, 1615, 1631, 1683, 1689, 1697, 1711,\n",
              "        1909, 1938, 1968, 2021, 2080, 2093, 2141, 2163, 2183, 2215, 2227, 2280,\n",
              "        2284, 2330, 2346, 2517, 2533, 2542, 2707, 2713, 2718, 3359, 4147, 4197,\n",
              "        4219, 4704, 4723, 4748], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsF5b3HdtbGt",
        "outputId": "1dd95e40-47d1-440c-cb2c-4504e946abaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import time\n",
        "total_accu = None"
      ],
      "outputs": [],
      "metadata": {
        "id": "KAN5TG4MgpHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print(f'! end of epoch {epoch:3} ! time: {time.time() - epoch_start_time:5.2}s ! '\n",
        "          f'valid accuracy {accu_val:8.3} ')\n",
        "    print('-' * 59)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4794])\n",
            "4794\n",
            "tensor([[ 0.1059, -0.0910,  0.0590,  ...,  0.1273,  0.0588, -0.1559],\n",
            "        [ 0.0111,  0.2785, -0.1334,  ...,  0.1429, -0.0829, -0.2774],\n",
            "        [-0.1504,  0.2112,  0.1732,  ...,  0.0989, -0.1133, -0.1295],\n",
            "        ...,\n",
            "        [-0.0333,  0.4788,  0.1249,  ..., -0.1241, -0.0938, -0.6595],\n",
            "        [-0.1239,  0.1493, -0.0536,  ..., -0.3682,  0.1406,  0.2889],\n",
            "        [-0.0159, -0.0856,  0.0706,  ..., -0.0393, -0.0110, -0.0698]],\n",
            "       device='cuda:0', grad_fn=<EmbeddingBagBackward>)\n",
            "torch.Size([64, 64])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-5ee987149864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0maccu_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_accu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtotal_accu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0maccu_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-137-5f687c667874>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-136-430527471c00>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, offsets)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    201\u001b[0m             raise RuntimeError(\n\u001b[1;32m    202\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 203\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "y8TbnNC2fc61",
        "outputId": "b4ef1ef3-d4ea-4e92-d6d2-3b667880db64"
      }
    }
  ]
}